{"cells":[{"cell_type":"markdown","source":["# Méthode de factorisation $\\mathrm{LU}$\n\n","*Note:* Dans ce paragraphe, nous montrons que la méthode de Gauss est équivalente à la factorisation de la matrice $A$ sous la forme d&#8217;un produit de deux matrices, $\\mathrm{A}=\\mathrm{LU}$, avec $\\mathrm{U}=\\mathrm{A}^{(n)}$.\n\n","Les matrices $\\mathrm{L}$ et $\\mathrm{U}$ ne dépendant que de $\\mathrm{A}$ (et non du second membre), la même factorisation peut être réutilisée quand on résout plusieurs systèmes linéaires ayant la même matrice A mais des seconds membres b différents. Le nombre d&#8217;opérations est alors considérablement réduit, puisque l&#8217;effort de calcul le plus important, environ $2 n^3 / 3$ flops, est dédié à la procédure d&#8217;élimination.\n\n","En posant\n\n","\n$$\n\\mathbf{m}_k=\\left(0, \\ldots, 0, m_{k+1, k}, \\ldots, m_{n, k}\\right)^T \\in \\mathbb{R}^n\n$$\n\n","et en définissant\n\n","\n$$\n\\mathrm{M}_k=\\left[\\begin{array}{cccccc}\n1 & \\ldots & 0 & 0 & \\ldots & 0 \\\\\n\\vdots & \\ddots & \\vdots & \\vdots & & \\vdots \\\\\n0 & & 1 & 0 & & 0 \\\\\n0 & & -m_{k+1, k} & 1 & & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & \\ldots & -m_{n, k} & 0 & \\ldots & 1\n\\end{array}\\right]=\\mathrm{I}_n-\\mathbf{m}_k \\mathbf{e}_k^T\n$$\n\n","comme la $k$-ième matrice de transformation de Gauss, on a\n\n","\n$$\n\\left(\\mathrm{M}_k\\right)_{i p}=\\delta_{i p}-\\left(\\mathbf{m}_k \\mathbf{e}_k^T\\right)_{i p}=\\delta_{i p}-m_{i k} \\delta_{k p}, \\quad i, p=1, \\ldots, n .\n$$\n\n","D&#8217;autre part, on a d&#8217;après [[eq18]](#eq18)\n\n","\n$$\na_{i j}^{(k+1)}=a_{i j}^{(k)}-m_{i k} \\delta_{k k} a_{k j}^{(k)}=\\sum_{p=1}^n\\left(\\delta_{i p}-m_{i k} \\delta_{k p}\\right) a_{p j}^{(k)}, \\quad i, j=k+1, \\ldots, n,\n$$\n\n","ou, de manière équivalente,\n\n","\n$$\n\\mathrm{A}^{(k+1)}=\\mathrm{M}_k \\mathrm{~A}^{(k)}\n$$\n\n","Par conséquent, à la fin du procédé d&#8217;élimination, on a construit les matrices $\\mathbf{M}_k, k=1, \\ldots, n-$ 1, et la matrice $\\mathrm{U}$ telles que\n\n","\n$$\n\\mathrm{M}_{n-1} \\mathrm{M}_{n-2} \\ldots \\mathrm{M}_1 \\mathrm{~A}=\\mathrm{U} .\n$$\n\n","Les matrices $\\mathrm{M}_k$ sont des matrices triangulaires inférieures dont les coefficients diagonaux valent 1 et dont l&#8217;inverse est donné par\n\n","\n$$\n\\mathrm{M}_k^{-1}=2 \\mathrm{I}_n-\\mathrm{M}_k=\\mathrm{I}_n+\\mathbf{m}_k \\mathbf{e}_k^T .\n$$\n\n","Les produits $\\left(\\mathbf{m}_i \\mathbf{e}_i^T\\right)\\left(\\mathbf{m}_j \\mathbf{e}_j^T\\right)$ étant nuls pour $i \\neq j$, on a :\n\n","\n$$\n\\begin{aligned}\n\\mathrm{A}= & \\mathrm{M}_1^{-1} \\mathrm{M}_2^{-1} \\ldots \\mathrm{M}_{n-1}^{-1} \\mathrm{U} \\\\\n= & \\left(\\mathrm{I}_n+\\mathbf{m}_1 \\mathbf{e}_1^T\\right)\\left(\\mathrm{I}_n+\\mathbf{m}_2 \\mathbf{e}_2^T\\right) \\ldots\\left(\\mathrm{I}_n+\\mathbf{m}_{n-1} \\mathbf{e}_{n-1}^T\\right) \\mathrm{U} \\\\\n= & \\left(\\mathrm{I}_n+\\sum_{i=1}^{n-1} \\mathbf{m}_i \\mathbf{e}_i^T\\right) \\mathrm{U} \\\\\n& {\\left[\\begin{array}{ccccc}\n1 & 0 & \\ldots & \\ldots & 0 \\\\\nm_{21} & 1 & & & \\vdots \\\\\n\\vdots & m_{32} & \\ddots & & \\vdots \\\\\n\\vdots & \\vdots & & \\ddots & 0 \\\\\nm_{n 1} & m_{n 2} & \\ldots & m_{n, n-1} & 1\n\\end{array}\\right] \\mathrm{U} . }\n\\end{aligned}\n$$\n\n","Posons $\\mathrm{L}=\\left(\\mathrm{M}_{n-1} \\mathrm{M}_{n-2} \\ldots \\mathrm{M}_1\\right)^{-1}=\\mathrm{M}_1^{-1} \\ldots \\mathrm{M}_{n-1}^{-1}$, on a alors\n\n","\n$$\n\\mathrm{A}=\\mathrm{LU} \\text {. }\n$$\n\n","Remarquons que, d&#8217;après [[eq22]](#eq22), les éléments sous-diagonaux de L sont les multiplicateurs $m_{i k}$ générés par la méthode de Gauss, tandis que les termes diagonaux sont égaux à 1.\n\n","Une fois calculées les matrices $\\mathrm{L}$ et $\\mathrm{U}$, résoudre le système linéaire consiste simplement à résoudre successivement les deux systèmes triangulaires\n\n","\n$$\n\\begin{aligned}\n& \\mathrm{Ly}=\\mathbf{b} \\\\\n& \\mathrm{Ux}=\\mathbf{y} .\n\\end{aligned}\n$$\n\n","Le coût de la factorisation est évidemment le même que celui de la méthode de Gauss.\n","Le résultat suivant établit un lien entre les mineurs principaux d&#8217;une matrice et sa factorisation LU induite par la méthode de Gauss.\n\n","Soit $\\mathrm{A} \\in \\mathbb{R}^{n \\times n}$. La factorisation $L U$ de $\\mathrm{A}$ avec $l_{i i}=1$ pour $i=1, \\ldots, n$ existe et est unique si et seulement si les sous-matrices principales $\\mathrm{A}_i$ de $\\mathrm{A}$ d&#8217;ordre $i=1, \\ldots, n-1$ sont inversibles.\n\n","*Note:* La liberté d&#8217;imposer les valeurs des termes diagonaux de $\\mathrm{L}$ ou de $\\mathrm{U}$ implique que plusieurs factorisations LU existent, chacune pouvant être déduite de l&#8217;autre par multiplication par une matrice diagonale convenable.\n"],"metadata":{"node_name":"admonition"}}],"metadata":{"language_info":{"name":"python","version":"3.9.1"},"kernelspec":{"name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":4}