{"cells":[{"cell_type":"markdown","source":["# Analyse de stabilité des systèmes linéaires\n\n","La résolution d&#8217;un système linéaire par une méthode numérique conduit invariablement à l&#8217;introduction d&#8217;erreurs d&#8217;arrondi.\n","Seule l&#8217;utilisation de méthodes stables peut éviter de détériorer la précision de la solution par la propagation de telles erreurs.\n","Dans cette section, nous analyserons la sensibilité de la solution du [le système matriciel](chap3/index.ipynb#nota:2) aux perturbations des données $A$ et $b$.\n","## Conditionnement d&#8217;une matrice\n\n","*Conditionnement d&#8217;une matrice*\\\n","Le conditionnement d&#8217;une matrice $\\mathrm{A} \\in \\mathbb{R}^{n \\times n}$ est défini par\n\n","\n$$\nK(\\mathrm{~A})=\\|\\mathrm{A}\\|\\left\\|\\mathrm{A}^{-1}\\right\\|\n$$\n\n","où $\\|\\cdot\\|$ est une norme matricielle subordonnée.\n","En général, $K(\\mathrm{~A})$ dépend du choix de la norme; ceci est signalé en introduisant un indice dans la notation, par exemple $K_{\\infty}(\\mathrm{A})=\\|\\mathrm{A}\\|_{\\infty}\\left\\|\\mathrm{A}^{-1}\\right\\|_{\\infty}$.\n","Plus généralement, $K_p(\\mathrm{~A})$ désigne le conditionnement de $\\mathrm{A}$ dans la $p$-norme.\n","Les cas remarquables sont $p=1, p=2$ et $p=\\infty$.\n","*Rappel sur le conditionnement*\\\n","Comme cela a déjà été noté dans le  [chapitre 1](chap1/index.ipynb), plus le conditionnement de la matrice est grand, plus la solution du système linéaire est sensible aux perturbations des données.\n","Commençons par noter que $K(\\mathrm{~A}) \\geq 1$ puisque\n","\n$$\n1=\\left\\|\\mathrm{AA}^{-1}\\right\\| \\leq\\|\\mathrm{A}\\|\\left\\|\\mathrm{A}^{-1}\\right\\|=K(\\mathrm{~A}) .\n$$\n","De plus, $K\\left(\\mathrm{~A}^{-1}\\right)=K(\\mathrm{~A})$ et $\\forall \\alpha \\in \\mathbb{R}$ avec $\\alpha \\neq 0, K(\\alpha \\mathrm{A})=K(\\mathrm{~A})$.\n","*Note:* Par convention, le conditionnement d&#8217;une matrice singulière est infini.\n","*Proposition: conditionnement  d&#8217;une matrice s.d.p*\\\n","Pour $p=2$ et dans le cas d&#8217;une matrice symétrique définie positive, on a\n\n","\n$$\nK_2(\\mathrm{~A})=\\frac{\\lambda_{\\max }}{\\lambda_{\\min }}=\\rho(\\mathrm{A}) \\rho\\left(\\mathrm{A}^{-1}\\right)\n$$\n\n","où $\\lambda_{\\max }$ est la plus grande valeur propre de $\\mathrm{A}$ et $\\lambda_{\\min }$ la plus petite.\n","*Preuve*\\\n","Pour établir [la proposition précédente](#prop:cond-sdp), remarquer que\n\n","\n$$\n\\|\\mathrm{A}\\|_2=\\rho(\\mathrm{A})=\\lambda_{\\max }\n$$\n\n","De plus, puisque $\\lambda\\left(\\mathrm{A}^{-1}\\right)=1 / \\lambda(\\mathrm{A})$, on obtient $\\left\\|\\mathrm{A}^{-1}\\right\\|_2=1 / \\lambda_{\\min }$ d&#8217;où l&#8217;on déduit le résultat.\n","*Note:* du fait de [la caractérisation du conditionnement d&#8217;une matrice s.d.p](#prop:cond-sdp), $K_2(\\mathrm{~A})$ est appelé ***conditionnement spectral***.\n","*Matrices mal conditionnées et matrices singulières*\\\n","On définit la distance relative de $\\mathrm{A} \\in \\mathbb{R}^{n \\times n}$ à l&#8217;ensemble des matrices singulières, par rapport à la p-norme, par\n\n","\n$$\n\\operatorname{dist}_p(\\mathrm{~A})=\\min \\left\\{\\frac{\\|\\delta \\mathrm{A}\\|_p}{\\|\\mathrm{~A}\\|_p}: \\mathrm{A}+\\delta \\mathrm{A} \\text { est singulière }\\right\\} .\n$$\n\n","On peut alors montrer que\n\n","\n$$\n\\operatorname{dist}_p(\\mathrm{~A})=\\frac{1}{K_p(\\mathrm{~A})}\n$$\n\n","L&#8217;équation précédente suggère qu&#8217;une matrice ayant un conditionnement élevé peut se comporter comme une matrice singulière de la forme $A+\\delta \\mathrm{A}$.\n","En d&#8217;autres termes, même si le membre de droite n&#8217;est pas perturbé, la solution peut l&#8217;être, puisque si $A+\\delta \\mathrm{A}$ est singulière, le système homogène $(\\mathrm{A}+\\delta \\mathrm{A}) \\mathrm{z}=0$ n&#8217;admet plus comme unique solution la solution nulle.\n\n","*Proposition : Inverse d&#8217;une matrice perturbée*\\\n","On peut aussi montrer que si\n\n","\n$$\n\\left\\|\\mathrm{A}^{-1}\\right\\|_p\\|\\delta \\mathrm{A}\\|_p < 1\n$$\n\n","alors $A+\\delta \\mathrm{A}$ est inversible.\n","*Conditionnement d&#8217;une matrice carrée*\\\n","Soit $A$ une matrice carrée, en utilisant np.linalg.cond permet de calculer le conditionnement de $A$ dans la norme $p$ (par défaut $p=2$).\n","voici les options de cette fonction:\n\n","\n","- $A$ : matrice carrée\n","- $p$ : norme utilisée pour le calcul du conditionnement. $p$ peut prendre les valeurs suivantes:\n","\n","| $p$ | norme utilisée |\n","| --- | -------------- |\n","| None | 2-norm, computed directly using the SVD |\n","| 'fro' | Frobenius norm |\n","| inf | max(sum(abs(x), axis=1)) |\n","| -inf | min(sum(abs(x), axis=1)) |\n","| 1 | max(sum(abs(x), axis=0)) |\n","| -1 | min(sum(abs(x), axis=0)) |\n","| 2 | 2-norm (largest sing. value) |\n","| -2 | smallest singular value |\n","\n","\n","*Exemple: calcul du conditionnement d&#8217;une matrice*\\\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import numpy as np\n","from numpy import linalg as LA\n","a = np.array([[1, 0, -1], [0, 1, 0], [1, 0, 1]])\n","c = LA.cond(a)\n","print(f\"cond(a)={c}\")\n","c = LA.cond(a, 'fro')\n","print(f\"cond(a, 'fro')={c}\")\n","c = LA.cond(a, np.inf)\n","print(f\"cond(a, np.inf)={c}\")\n","c = LA.cond(a, -np.inf)\n","print(f\"cond(a, -np.inf)={c}\")\n","c = LA.cond(a, 1)\n","print(f\"cond(a, 1)={c}\")\n","c = LA.cond(a, -1)\n","print(f\"cond(a, -1)={c}\")\n","c = LA.cond(a, 2)\n","print(f\"cond(a, 2)={c}\")\n","c = LA.cond(a, -2)\n","print(f\"cond(a, -2)={c}\")\n","c = min(LA.svd(a, compute_uv=False))*min(LA.svd(LA.inv(a), compute_uv=False)) <1>\n","print(f\"cond(a)={c}\")\n"]},{"cell_type":"markdown","source":["\n1. Le conditionnement d'une matrice est le produit des valeurs singulières maximale et minimale de la matrice et de son inverse. Les vecteurs singuliers ne sont pas calculés.","\n","## Analyse de stabilité\n\n","Nous introduisons une mesure de la sensibilité du système aux perturbations des données.\n","Ces perturbations seront interprétées comme étant les effets des erreurs d&#8217;arrondi induites par la méthode numérique utilisée pour résoudre le système.\n","A cause des erreurs d&#8217;arrondi, une méthode numérique pour résoudre [le système matriciel](chap3/index.ipynb#nota:2) ne fournit pas la solution exacte mais seulement une solution approchée qui satisfait un système perturbé.\n","En d&#8217;autres termes,\n","*Méthode numérique pour résoudre un système linéaire perturbé*\\\n","une méthode numérique fournit une solution (exacte) $\\mathbf{x}+\\boldsymbol{\\delta} \\mathbf{x}$ du système perturbé\n\n","\n$$\n(\\mathrm{A}+\\delta \\mathrm{A})(\\mathbf{x}+\\delta \\mathbf{x})=\\mathbf{b}+\\delta \\mathbf{b}.\n$$\n","Le résultat suivant donne une estimation de $\\delta \\mathbf{x}$ en fonction de $\\delta \\mathrm{A}$ et $\\delta \\mathbf{b}$.\n","*Théorème: estimation de l&#8217;erreur*\\\n","Soit $\\mathrm{A} \\in \\mathbb{R}^{n \\times n}$ une matrice inversible et $\\delta \\mathrm{A} \\in \\mathbb{R}^{n \\times n}$ telles que l&#8217;inégalité [pour garantir que le problème soit inversible](#prop:pbperturbe) soit satisfaite pour une norme matricielle subordonnée $\\|\\cdot\\|$.\n\n","Si $\\mathbf{x} \\in \\mathbb{R}^n$ est la solution de $\\mathrm{A} \\mathbf{x}=\\mathbf{b}$ avec $\\mathbf{b} \\in \\mathbb{R}^n(\\mathbf{b} \\neq \\mathbf{0})$ et si $\\delta \\mathbf{x} \\in \\mathbb{R}^n$ satisfait [[eq8]](#eq8) pour $\\delta \\mathbf{b} \\in \\mathbb{R}^n$,\n","alors\n\n","\n$$\n\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leq \\frac{K(\\mathrm{~A})}{1-K(\\mathrm{~A})\\|\\delta \\mathrm{A}\\| /\\|\\mathrm{A}\\|}\\left(\\frac{\\|\\delta \\mathbf{b}\\|}{\\|\\mathbf{b}\\|}+\\frac{\\|\\delta \\mathrm{A}\\|}{\\|\\mathrm{A}\\|}\\right)\n$$\n","*Preuve*\\\n","D&#8217;après [résultat l&#8217;inverse du problème perturbé](#prop:pbperturbe), la matrice $\\mathrm{A}^{-1} \\delta \\mathrm{A}$ a une norme inférieure à 1 . Ainsi $\\mathrm{I}+\\mathrm{A}^{-1} \\delta \\mathrm{A}$ est inversible et\n\n","\n$$\n\\left\\|\\left(\\mathrm{I}+\\mathrm{A}^{-1} \\delta \\mathrm{A}\\right)^{-1}\\right\\| \\leq \\frac{1}{1-\\left\\|\\mathrm{A}^{-1} \\delta \\mathrm{A}\\right\\|} \\leq \\frac{1}{1-\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\delta \\mathrm{A}\\|} .\n$$\n\n","D&#8217;autre part, en résolvant [[eq8]](#eq8) en $\\delta \\mathbf{x}$ et en rappelant que $\\mathrm{Ax}=\\mathbf{b}$, on obtient\n\n","\n$$\n\\delta \\mathbf{x}=\\left(\\mathrm{I}+\\mathrm{A}^{-1} \\delta \\mathrm{A}\\right)^{-1} \\mathrm{~A}^{-1}(\\delta \\mathbf{b}-\\delta \\mathrm{A} \\mathbf{x}) .\n$$\n\n","En passant aux normes et en utilisant [les relations ci-dessus](#eq10), on a donc\n\n","\n$$\n\\|\\delta \\mathbf{x}\\| \\leq \\frac{\\left\\|\\mathrm{A}^{-1}\\right\\|}{1-\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\delta \\mathrm{A}\\|}(\\|\\delta \\mathbf{b}\\|+\\|\\delta \\mathrm{A}\\|\\|\\mathbf{x}\\|) .\n$$\n\n","Enfin, en divisant les deux membres par $\\|\\mathbf{x}\\|$ (qui est non nul puisque $\\mathbf{b} \\neq \\mathbf{0}$ et $\\mathrm{A}$ est inversible) et en remarquant que $\\|\\mathbf{x}\\| \\geq\\|\\mathbf{b}\\| /\\|\\mathrm{A}\\|$, on obtient le résultat voulu.\n","*Remarque: estimation de l&#8217;erreur*\\\n","Dans l'[equation ci-dessus](#eq9) , on peut modéliser le terme $c=\\frac{K(\\mathrm{~A})}{1-K(\\mathrm{~A})\\|\\delta \\mathrm{A}\\| /\\|\\mathrm{A}\\|}$ par $c(t)=\\frac{t}{1-\\epsilon t}$ ou $t=K(\\mathrm{~A})$ et $\\epsilon=\\|\\delta \\mathrm{A}\\| /\\|\\mathrm{A}\\|$.\n","Admettons que $\\epsilon$ est petit et observez que la fonction $c(t):[1, \\infty) \\rightarrow \\mathbb{R}$ est strictement croissant.\n","Donc une augmentation du conditionnement de la matrice $A$ implique une augmentation de la borne de l&#8217;estimation dans cette [equation](#eq9).\n","Voici un cas particulier du Théorème précédent.\n","*Théorème: Cas particulier $\\delta \\mathrm{A}=0$*\\\n","Supposons que les conditions du [Théorème précédent](#thm_esterr) soient remplies et posons $\\delta \\mathrm{A}=0$. Alors\n\n","\n$$\n\\frac{1}{K(\\mathrm{~A})} \\frac{\\|\\delta \\mathbf{b}\\|}{\\|\\mathbf{b}\\|} \\leq \\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leq K(\\mathrm{~A}) \\frac{\\|\\delta \\mathbf{b}\\|}{\\|\\mathbf{b}\\|} .\n$$\n","*Preuve*\\\n","Nous prouvons seulement la première inégalité puisque la seconde découle directement de [cette équation](#eq9).\n","La relation $\\delta \\mathbf{x}=\\mathrm{A}^{-1} \\delta \\mathbf{b}$ implique $\\|\\delta \\mathbf{b}\\| \\leq\\|\\mathrm{A}\\|\\|\\delta \\mathbf{x}\\|$.\n","En multipliant les deux membres par $\\|\\mathbf{x}\\|$ et en rappelant que $\\|\\mathbf{x}\\| \\leq\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\mathbf{b}\\|$, il vient $\\|\\mathbf{x}\\|\\|\\delta \\mathbf{b}\\| \\leq K(\\mathrm{~A})\\|\\mathbf{b}\\|\\|\\delta \\mathbf{x}\\|$, qui est l&#8217;inégalité voulue.\n","En vue d&#8217;utiliser les inégalités [[eq10]](#eq10) et [[eq11]](#eq11) pour l&#8217;analyse de la propagation des erreurs d&#8217;arrondi dans le cas des méthodes directes, $\\|\\delta \\mathrm{A}\\|$ et $\\|\\delta \\mathbf{b}\\|$ doivent être majorés en fonction de la dimension du système et des caractéristiques de l&#8217;arithmétique à virgule flottante.\n","Il est en effet raisonnable de s&#8217;attendre à ce que les perturbations induites par une méthode de résolution soient telles que $\\|\\delta \\mathrm{A}\\| \\leq \\gamma\\|\\mathrm{A}\\|$ et $\\|\\delta \\mathbf{b}\\| \\leq \\gamma\\|\\mathbf{b}\\|$, $\\gamma$ étant un nombre positif qui dépend de l&#8217;unité d&#8217;arrondi $u$ (définie dans le chapitre 1).\n","Par exemple, nous supposerons dorénavant que $\\gamma=\\beta^{1-t}$, où $\\beta$ est la base et $t$ le nombre de chiffres significatifs de la mantisse du système $\\mathbb{F}$ des nombres à virgule flottante. Dans ce cas, on peut compléter [[eq9]](#eq9) par le théorème suivant.\n","*Théorème: estimation de l&#8217;erreur*\\\n","Supposons que $\\|\\delta \\mathrm{A}\\| \\leq \\gamma\\|\\mathrm{A}\\|,\\|\\delta \\mathbf{b}\\| \\leq \\gamma\\|\\mathbf{b}\\|$ avec $\\gamma \\in \\mathbb{R}^{+}$et $\\delta \\mathrm{A} \\in \\mathbb{R}^{n \\times n}$, $\\delta \\mathbf{b} \\in \\mathbb{R}^n$. Alors, si $\\gamma K(\\mathrm{~A})<1$, on a les inégalités suivantes :\n\n","\n$$\n\\begin{gathered}\n\\frac{\\|\\mathbf{x}+\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leq \\frac{1+\\gamma K(\\mathrm{~A})}{1-\\gamma K(\\mathrm{~A})} \\\\\n\\frac{\\|\\delta \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\leq \\frac{2 \\gamma}{1-\\gamma K(\\mathrm{~A})} K(\\mathrm{~A}) .\n\\end{gathered}\n$$\n","*Preuve*\\\n","* **Montrons la première relation de [[eq12]](#eq12)**\\\nD&#8217;après [[eq8]](#eq8),\n\n  \n$$\n\\left(\\mathrm{I} + \\mathrm{A}^{-1} \\delta \\mathrm{A}\\right)(\\mathbf{x} + \\delta \\mathbf{x})=\\mathbf{x} + \\mathrm{A}^{-1} \\delta \\mathbf{b}].\n$$\n\n  De plus, puisque $\\gamma K(\\mathrm{~A})<1$ et $\\|\\delta \\mathrm{A}\\| \\leq \\gamma\\|\\mathrm{A}\\|, \\mathrm{I} + \\mathrm{A}^{-1} \\delta \\mathrm{A}$ est inversible. En prenant l&#8217;inverse de cette matrice et en passant aux normes, on obtient\n\n  \n$$\n\\|\\mathbf{x} + \\delta \\mathbf{x}\\| \\leq\\left\\|\\left(\\mathrm{I} + \\mathrm{A}^{-1} \\delta \\mathrm{A}\\right)^{-1}\\right\\|\\left(\\|\\mathbf{x}\\| + \\gamma\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\mathbf{b}\\|\\right)\n$$\n\n  Alors\n\n  \n$$\n\\|\\mathbf{x}+\\delta \\mathbf{x}\\| \\leq \\frac{1}{1-\\left\\|\\mathrm{A}^{-1} \\delta \\mathrm{A}\\right\\|}\\left(\\|\\mathbf{x}\\|+\\gamma\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\mathbf{b}\\|\\right),\n$$\n\n  ce qui implique la première relation de [[eq12]](#eq12), puisque $\\left\\|\\mathrm{A}^{-1} \\delta \\mathrm{A}\\right\\| \\leq \\gamma K(\\mathrm{~A})$ et $\\|\\mathbf{b}\\| \\leq\\|\\mathrm{A}\\|\\|\\mathbf{x}\\|$.\n\n\n* **Montrons la deuxième relation de [[eq12]](#eq12)**\\\nEn retranchant [le problème initial](chap3/index.ipynb#nota:2) de [[eq8]](#eq8), on a\n\n  \n$$\n\\mathrm{A} \\delta \\mathbf{x}=-\\delta \\mathrm{A}(\\mathbf{x}+\\delta \\mathbf{x})+\\delta \\mathbf{b}\n$$\n\n  En prenant l&#8217;inverse de A et en passant aux normes, on obtient l&#8217;inégalité suivante\n\n  \n$$\n\\begin{aligned}\n\\|\\delta \\mathbf{x}\\| & \\leq\\left\\|\\mathrm{A}^{-1} \\delta \\mathrm{A}\\right\\|\\|\\mathbf{x}+\\delta \\mathbf{x}\\|+\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\delta \\mathbf{b}\\| \\\\\n& \\leq \\gamma K(\\mathrm{~A})\\|\\mathbf{x}+\\delta \\mathbf{x}\\|+\\gamma\\left\\|\\mathrm{A}^{-1}\\right\\|\\|\\mathbf{b}\\| .\n\\end{aligned}\n$$\n\n  En divisant les deux membres par $\\|\\mathbf{x}\\|$ et en utilisant l&#8217;inégalité triangulaire $\\|\\mathbf{x} + \\delta \\mathbf{x}\\| \\leq\\|\\delta \\mathbf{x}\\| + \\|\\mathbf{x}\\|$, on obtient finalement la deuxième relation de [[eq12]](#eq12).\n\n\n"],"metadata":{"node_name":"colist"}}],"metadata":{"language_info":{"name":"python","version":"3.9.1"},"kernelspec":{"name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":4}