{"cells":[{"cell_type":"markdown","source":["# Méthodes itératives : methodes de splitting\n\n","## La méthode de Jacobi\n\n","On remarque que si les éléments diagonaux de $A$ sont non nuls, le système linéaire $A\\mathbf{x}=\\mathbf{b}$ est équivalent à :\n","\n$$\n\\label{eq}\nx_i=\\frac{1}{a_{ii}}\\left(b_i-\\sum_{j=1,j\\neq\ni}^na_{ij}x_j\\right),\\,\\,\\,\\,\\,i=1,\\ldots,n.\n$$\n","Pour une donnée initiale $\\mathbf{x}^{(0)}$ choisie, on calcule $\\mathbf{x}^{(k+1)}$ par\n","\n$$\n\\label{jac}\nx_i^{(k+1)}=\\frac{1}{a_{ii}}\\left(b_i-\\sum_{j=1,j\\neq i}^na_{ij}x_j^{(k)}\\right)\n,\\,\\,\\,\\,\\,i=1,\\ldots,n.\n$$\n","Cela permet d&#8217;identifier le *splitting* suivant pour $A$ :\n","\n$$\nP=D,\\quad N=D-A=E+F,\n$$\n","où $D$ est la matrice diagonale avec sur la diagonale les éléments diagonaux de $A$, $E$ est la matrice $E=(e_{ij})$ triangulaire inférieure\n","\n$$\n\\begin{cases}\ne_{ij}=-a_{ij} &\\quad\\rm{ si} \\,\\, i>j\\\\\ne_{ij}=0       &\\quad \\rm{ si} \\,\\, i\\leq j,\n\\end{cases}, \\quad\nE=\\begin{bmatrix} 0 &   0 & 0&\\ldots &0\\\\\n              -a_{21} &   0  & 0&\\ldots &0\\\\\n              -a_{31} & -a_{32} & 0 &\\ldots&0 \\\\\n               \\vdots     & \\vdots    & \\ddots & \\ddots     & \\vdots \\\\\n               -a_{n1}& -a_{n2} & \\ldots& -a_{nn-1}& 0\n\\end{bmatrix}\n$$\n","$F$ est la matrice $F=(f_{ij})$ triangulaire supérieure\n","\n$$\n\\begin{cases}\nf_{ij}=-a_{ij} &\\quad \\rm{ si} \\,\\, j>i\\\\\nf_{ij}=0       &\\quad \\rm{ si} \\,\\, j\\leq i.\n\\end{cases}, \\quad\nF=\\begin{bmatrix} 0 &   -a_{12} & -a_{13}&\\ldots &-a_{1n}\\\\\n              0 &   0    & -a_{23}&\\ldots &-a_{2n}\\\\\n              0 &    0 & 0    &\\ddots  & \\vdots  \\\\\n               \\vdots     & \\vdots    & \\ddots & \\ddots     & -a_{n-1n} \\\\\n               0& 0 & \\ldots& 0& 0\n\\end{bmatrix}\n$$\n","On a alors que $A=D-(E+F)$.\n","$B_J$ et $g$ de la méthode de Jacobi sont données par :\n","\n$$\nB_J = D^{-1}(E+F)=I-D^{-1}A, \\quad g_J = D^{-1}\\mathbf{b}.\n$$\n\n","## La méthode de Gauss-Seidel\n\n","Pour cette méthode on a\n","\n$$\n\\label{gs}\nx_i^{(k+1)}=\\frac{1}{a_{ii}}\\left(b_i-\\sum_{j=1}^{i-1}a_{ij}x_j^{(k+1)}-\n\\sum_{j=i+1}^na_{ij}x_j^{(k)}\\right)\n,\\,\\,\\,\\,\\,i=1,\\ldots,n.\n$$\n","Dans ce cas, le *splitting* de $A$ est\n","\n$$\nP=D-E,\\,\\,\\,N=F,\n$$\n","et donc la matrice d&#8217;itération et $g$  sont données par\n","\n$$\nB_{GS} = (D-E)^{-1}F,\\quad g_{GS} = (D-E)^{-1}\\mathbf{b}.\n$$\n\n","## La méthode de relaxation SOR (Successive over-relaxation)\n\n","Pour un paramètre $\\omega$ (dit de *relaxation*), on définit\n","\n$$\n\\label{sor}\nx_i^{(k+1)}=\\frac{\\omega}{a_{ii}}\\left(b_i-\\sum_{j=1}^{i-1}a_{ij}x_j^{(k+1)}-\n\\sum_{j=i+1}^na_{ij}x_j^{(k)}\\right)+(1-\\omega)x_i^{(k)}\n,\\,\\,\\,\\,\\,i=1,\\ldots,n.\n$$\n","Cela se traduit par la relation\n","\n$$\nx_i^{(k+1)}=\\omega x_{i,GS}^{(k+1)}+ (1-\\omega)x_{i}^{(k)},\n$$\n","où $x_{i,GS}^{(k+1)}$ et la valeur de la $i$-ème composante qu&#8217;on obtient en utilisant la formule [[eq7]](#eq7).\n","Cette méthode s&#8217;écrit sous forme vectorielle comme\n","\n$$\n(I-\\omega D^{-1}E)\\mathbf{x}^{(k+1)}=\n  [(1-\\omega)I+\\omega D^{-1}F]\\mathbf{x}^{(k)}+\\omega D^{-1}\\mathbf{b},\n$$\n","d&#8217;où la matrice d&#8217;itération $B(\\omega)$ et $g(\\omega)$\n","\n$$\nB(\\omega)=(I-\\omega D^{-1}E)^{-1}[(1-\\omega)I+\\omega D^{-1}F], \\quad g(\\omega) = \\omega D^{-1}\\mathbf{b}.\n$$\n","Cette méthode coïncide pour $\\omega=1$ avec la méthode de Gauss-Seidel.\n","*Note:* Si $\\omega\\in(0,1)$ la méthode est dite de *sous-relaxation* tandis que si $\\omega>1$ elle est appelée de *sur-relaxation*.\n\n","## Quelques résultats de convergence\n\n","On a les résultats suivants.\n","Théorème: Condition suffisante pour la convergence de la méthode de Jacobi et Gauss-Seidel\n","Si $A$ est une ***matrice à diagonale dominante stricte par lignes***, alors les méthodes de Jacobi et de Gauss-Seidel sont convergentes.\n","*Preuve*\\\n","* **Cas de Jacobi**\\\nLa matrice $A$ étant à diagonale dominante stricte, on a par définition $\\displaystyle  \\forall 1\\leq i\\leq n,\\quad|a_{ii}|>\\sum_{j\\neq\ni}|a_{ij}|$. Par conséquent,\n\n  \n$$\n\\|B_J\\|_{\\infty}=\\max_{i}\\sum_{j}|b_{ij}|=\\max_{i}\\sum_{j\\neq i}\\frac{|a_{ij}|}{|a_{ii}|} < 1\n$$\n\n  et comme $\\rho(B_J)\\leq\\|B_J\\|_{\\infty} <1$ on obtient la convergence de la méthode de Jacobi. $\\Box$\n\n\n","*Théorème : Condition suffisante pour la convergence de la méthode de Gauss-Seidel*\\\n","Si $A$ est une ***matrice symétrique définie positive***, alors la méthode de Gauss-Seidel converge de manière monotone pour la norme $\\| \\cdot \\|_A$ (la méthode de Jacobi pas forcément).\n","*Preuve*\\\n","Voir le Théorème 4.5 du livre de Quarteroni et Sacco, p. 121. $\\Box$\n","*Théorème : Condition nécessaire et condition suffisante pour la convergence de la méthode SOR*\\\n","\n","1. Une *condition nécessaire* pour assurer la convergence de la méthode SOR est que $0<\\omega<2$.\n","1. Si $A$ est une ***matrice symétrique définie positive***, alors une telle *condition est aussi suffisante* pour la convergence.\n","\n","*Preuve*\\\n","En effet, comme latexmath:[B(\\omega)=(I-\\omega\n","D{-1}E){-1}[(1-\\omega)I+\\omega D^{-1}F]], on tire que\n\n","\n$$\n\\det B(\\omega)=\\underbrace{\\det(I-\\omega D^{-1}E)^{-1}}_{\\displaystyle=1}\\det[(1-\\omega)I+\\omega D^{-1}F]=(1-\\omega)^n\n$$\n\n","Ainsi, en notant avec $\\lambda_i$ les valeurs propres de $B(\\omega)$, on obtient que\n\n","\n$$\n|\\lambda_{max}|^n\\geq|\\prod_{i=1}^n\\lambda_i|=|1-\\omega|^n\n$$\n\n","ce qui donne que $\\rho(B(\\omega))\\geq |\\omega -1|$. Donc si la méthode converge on a $|\\omega -1|<1$, soit donc $0<\\omega<2$. $\\Box$\n","*Théorème: paramètre optimal pour SOR*\\\n","\n","1. Si $A$ est à **diagonale dominante stricte**, alors la méthode SOR converge si $0<\\omega\\leq 1$.\n","1. Dans le cas particulier où $A$ est **symétrique définie positive et tridiagonale**, alors le paramètre $\\omega$ optimal pour la méthode SOR est donné par :\n","\n\n","\n$$\n\\label{omegaopt}\n\\omega_{opt}=\\frac{2}{1+\\sqrt{1-\\rho(B_J)^2}}.\n$$\n","## Implémentations en {python}\n\n","## Jacobi\n\n","Voici deux implémentations de la méthode de Jacobi en {python}.\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["Unresolved directive in 3-splitting.adoc - include::example$tan/syslin/jacobi.py[]\n"]},{"cell_type":"markdown","source":["\n1. nous implémentons `jacobi1` en  utilisant <<eq:2>>","\n2. nous implémentons `jacobi2` en utilisant la forme algébrique <<eq:3>> de stem:[B_J] et stem:[g_J]","\n3. nous appliquons la méthode itérative pour calculer les itérés.","","## Gauss-Seidel\n\n","Voici deux implémentations de la méthode de Gauss-Seidel en {python}.\n"],"metadata":{"node_name":"colist"}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["Unresolved directive in 3-splitting.adoc - include::example$tan/syslin/gauss_seidel.py[]\n"]},{"cell_type":"markdown","source":["\n1. nous utilisons `scipy.linalg.solve_triangular` pour résoudre le système triangulaire inférieur associé à la méthode de Gauss-Seidel stem:[(D-E)^{-1}]","\n2. nous implémentons `gauss_seidel1` en  utilisant <<eq7>>","\n3. nous implémentons `gauss_seidel2` en utilisant la forme algébrique <<eq8>>","","## SOR\n\n","Voici deux implémentations de la méthode de relaxation SOR en {python}.\n"],"metadata":{"node_name":"colist"}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["Unresolved directive in 3-splitting.adoc - include::example$tan/syslin/sor.py[]\n"]},{"cell_type":"markdown","source":["\n1. nous utilisons `scipy.linalg.solve_triangular` pour résoudre les systèmes triangulaire.","\n2. nous implémentons `sor1` en  utilisant <<eq:sor:1>>","\n3. nous implémentons `sor2` en utilisant la forme algébrique <<eq:sor:2>>","\n4. dans le cas de `sor2` nous utilisons la fonction `solve_triangular` de la bibliothèque `scipy.linalg` pour résoudre le système triangulaire.","","## Exemples\n\n","Dans les sections suivantes nous utiliserons les matrices suivantes :\n","*Exemple 1*\\\n","Soit $A$ une matrice à diagonale dominante stricte par ligne\n\n","\n$$\nA=\\begin{pmatrix}\n5 & 1 & 1 & -1 \\\\\n1 & 5 & 1 & -2 \\\\\n1 & 1 & 6 & 1 \\\\\n-1 & 2 & 1 & 7\n\\end{pmatrix}.\n$$\n\n","On a alors :\n\n","\n$$\nD=\\begin{pmatrix}\n5 & 0 & 0 & 0 \\\\\n0 & 5 & 0 & 0\\\\\n0 & 0 & 6 & 0\\\\\n0 & 0 & 0 & 7\n\\end{pmatrix},\n\\quad\nE=\\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n-1 & 0 & 0 & 0\\\\\n-1 & -1 & 0 & 0\\\\\n1 & -2 & -1 & 0\n\\end{pmatrix},\n\\quad\nF=\\begin{pmatrix}\n0 & -1 & -1 & 1 \\\\\n0 & 0 & -1 & -2\\\\\n0 & 0 & 0 & -1\\\\\n0 & 0 & 0 & 0\n\\end{pmatrix}.\n$$\n\n","Pour extraire de la matrice $A$ les trois matrices $D$, $E$ et $F$ en Python on utilise le code suivant :\n"],"metadata":{"node_name":"colist"}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["D=np.diag(np.diag(A))\n","E=-(np.tril(A),-1)\n","F=-(np.triu(A),1)\n"]},{"cell_type":"markdown","source":["Nous avons donc\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import numpy as np\n","\n","# A est a diagonale dominante stricte\n","\n","A=np.array([[5, 1, 1, -1],\n","            [1, 5, 1, -2],\n","            [1, 1, 6, 1],\n","            [-1, 2, 1, 7]])\n","\n","# Extract the diagonal of A\n","D = np.diag(np.diag(A))\n","\n","# Extract the lower triangular part of A and subtract D\n","E = -np.tril(A,-1)\n","\n","# Extract the upper triangular part of A and subtract D\n","F = -np.triu(A,1)\n","\n","print(\"D:\\n\", D)\n","print(\"E:\\n\", E)\n","print(\"F:\\n\", F)\n","# we compute the iteration matrix\n","B = np.linalg.inv(D).dot(E+F)\n","print(\"B:\\n\", B)\n","# we compute the spectral radius of B\n","rho = np.max(np.abs(np.linalg.eigvals(B)))\n","print(\"rho:\\n\", rho)\n"]},{"cell_type":"markdown","source":["Considérons à présent une matrice $A_{sdp}$ symétrique définie positive.\n","Soit la matrice $A$ suivante :\n\n","\n$$\nA_{sdp}=\\begin{pmatrix}\n5 & 1 & 1 & -1 \\\\\n1 & 5 & 2 & 0.5\\\\\n1 & 2 & 4 & 1\\\\\n-1 & 0.5 & 1 & 6\n\\end{pmatrix}.\n$$\n\n","Vérifions que $A$ est symétrique définie positive.\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["A_sdp = np.array([[5, 1, 1, -1],\n","              [1, 5, 2, 0.5],\n","              [1, 2, 4, 1],\n","              [-1, 0.5, 1, 6]])\n","# verifions qu'elle est s.d.p\n","sdp  = np.allclose( A_sdp, A_sdp.T )\n","sdp &= np.all( np.linalg.eigvals(A_sdp) > 0 )\n","print(f\"A_sdp est symétrique définie positive: {sdp}\")\n","assert sdp == True\n","\n","D_sdp = np.diag(np.diag(A_sdp))\n","E_sdp = -np.tril(A_sdp,-1)\n","F_sdp = -np.triu(A_sdp,1)\n"]},{"cell_type":"markdown","source":["Dans ce qui suit nous vérifions systématiquement le rayon spectrale, grâce à fonction suivante:\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["def spectral_radius(B):\n","    rho = np.max(np.abs(np.linalg.eigvals(B)))\n","    return rho\n","\n","def is_convergent(B):\n","    rho = spectral_radius(B)\n","    return rho < 1\n"]},{"cell_type":"markdown","source":["## Jacobi\n\n","Nous pouvons maintenant appliquer la méthode de Jacobi pour résoudre le système $A\\mathbf{x}=\\mathbf{b}$.\n","Considérons la première matrice $A$ de l&#8217;exemple [[ex:1]](#ex:1).\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import numpy as np\n","from tan.syslin.jacobi import jacobi1,jacobi2\n","import time\n","\n","# vérifions le rayon spectral\n","B_J = np.linalg.inv(D).dot(E+F)\n","print(f\"Jacobi converge: {is_convergent(B_J)}\")\n","\n","# testons les méthodes de Jacobi\n","for jacobi in [jacobi1,jacobi2]:\n","    print(f\"\\n** jacobi={jacobi.__name__}\")\n","    t = time.time()\n","    [x_j, niter_j, inc_j] = jacobi(A, np.ones(4), np.zeros(4), 1e-6, 100)\n","    t_end = time.time()\n","    print(f\"time={t_end-t:.3e}s\")\n","    print(f\"x_j:\\n{x_j}\")\n","    print(f\"niter_j:\\n{niter_j}\")\n","    print(f\"inc_j:\\n{inc_j}\")\n"]},{"cell_type":"markdown","source":["## Gauss-Seidel\n\n","Appliquer la méthode Gauss-Seidel pour résoudre le système $A\\mathbf{x}=\\mathbf{b}$.\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import numpy as np\n","from tan.syslin.gauss_seidel import gauss_seidel1, gauss_seidel2\n","import time\n","\n","B_GS = np.linalg.inv(D-E).dot(F)\n","print(f\"Gauss-Seidel converge: {is_convergent(B_GS)}\")\n","\n","for gauss_seidel in [gauss_seidel1, gauss_seidel2]:\n","    print(f\"\\n** gauss_seidel={gauss_seidel.__name__}\")\n","    t = time.time()\n","    [x_gs, niter_gs, inc_gs] = gauss_seidel(A, np.ones(4), np.zeros(4), 1e-6, 100)\n","    t_end = time.time()\n","    print(f\"time={t_end-t:.3e}s\")\n","    print(f\"x_gs:\\n{x_gs}\")\n","    print(f\"niter_gs:\\n{niter_gs}\")\n","    print(f\"inc_gs:\\n{inc_gs}\")\n"]},{"cell_type":"markdown","source":["## SOR\n\n","On applique la méthode SOR pour résoudre le système latexmath :[A\\mathbf{x}=\\mathbf{b}].\n\n","Dans un premier temps nous prenons une valeur de $\\omega < 1$ (sous relaxation)\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import numpy as np\n","import scipy.linalg\n","from tan.syslin.sor import sor1,sor2\n","import time\n","\n","omega = 0.9\n","invD = np.diag(1./np.diag(D))\n","B_SOR = scipy.linalg.solve_triangular(np.eye(len(A))-omega*invD@E,(1-omega)*np.eye(len(A))+omega*invD@F, lower=True)\n","print(f\"SOR converge: {is_convergent(B_SOR)}\")\n","\n","for sor in [sor1,sor2]:\n","    print(f\"\\n** sor={sor.__name__}\")\n","    t = time.time()\n","    [x_sor, niter_sor, inc_sor] = sor(A, np.ones(4), np.zeros(4), omega=0.9, tol=1e-6, maxiter=100)\n","    t_end = time.time()\n","    print(f\"time={t_end-t:.3e}s\")\n","    print(f\"x_sor:\\n{x_sor}\")\n","    print(f\"niter_sor:\\n{niter_sor}\")\n","    print(f\"inc_sor:\\n{inc_sor}\")\n"]},{"cell_type":"markdown","source":["Puis, nous prenons une valeur de $\\omega > 1$ (sur relaxation)\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["omega = 1.1\n","invD = np.diag(1./np.diag(D))\n","B_SOR = scipy.linalg.solve_triangular(np.eye(len(A))-omega*invD@E,(1-omega)*np.eye(len(A))+omega*invD@F, lower=True)\n","print(f\"SOR converge: {is_convergent(B_SOR)}\")\n","\n","for sor in [sor1,sor2]:\n","    print(f\"\\n** sor={sor.__name__}\")\n","    t = time.time()\n","    [x_sor_sur, niter_sor_sur, inc_sor_sur] = sor(A, np.ones(4), np.zeros(4), omega=1.1, tol=1e-6, maxiter=100)\n","    t_end = time.time()\n","    print(f\"time={t_end-t:.3e}s\")\n","    print(f\"x_sor_sur:\\n{x_sor_sur}\")\n","    print(f\"niter_sor_sur:\\n{niter_sor_sur}\")\n","    print(f\"inc_sor_sur:\\n{inc_sor_sur}\")\n"]},{"cell_type":"markdown","source":["*Note:* dans les deux cas (sur et sous relaxation) avec $0 < \\omega < 2$, la méthode SOR converge.\n\n","Nous pouvons comparer l&#8217;ensemble des méthodes, jacobi, gauss-seidel et sor pour l&#8217;exemple donné, tracons avec `plotly` les incréments en fonction du nombre d&#8217;itérations en mode `semilogy`\n"],"metadata":{"node_name":"admonition"}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=np.arange(niter_j + 1), y=inc_j, mode='lines+markers', name='Jacobi'))\n","fig.add_trace(go.Scatter(x=np.arange(niter_gs + 1), y=inc_gs, mode='lines+markers', name='Gauss-Seidel'))\n","fig.add_trace(go.Scatter(x=np.arange(niter_sor + 1), y=inc_sor, mode='lines+markers', name='SOR sous relaxation'))\n","fig.add_trace(go.Scatter(x=np.arange(niter_sor_sur + 1), y=inc_sor_sur, mode='lines+markers', name='SOR sur relaxation'))\n","fig.update_layout(title='Incréments en fonction du nombre d\\'itérations', xaxis_title='Nombre d\\'itérations', yaxis_title='Incrément',yaxis_type=\"log\")\n","fig.show()\n"]},{"cell_type":"markdown","source":["Testons à présent le cas où la condition nécessaire n&#8217;est pas vérifiée, i.e $\\omega > 2$ (sur relaxation) afin de vérifier [la condition nécessaire $0 < \\omega < 2$](#thm:3)\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["omega = 2.1\n","invD = np.diag(1./np.diag(D))\n","B_SOR = scipy.linalg.solve_triangular(np.eye(len(A))-omega*invD@E,(1-omega)*np.eye(len(A))+omega*invD@F, lower=True)\n","print(f\"SOR converge: {is_convergent(B_SOR)}\")\n","\n","for sor in [sor1,sor2]:\n","    print(f\"\\n** sor={sor.__name__}\")\n","    t = time.time()\n","    [x_sor, niter_sor, inc_sor] = sor(A, np.ones(4), np.zeros(4), omega=2.1, tol=1e-6, maxiter=100)\n","    t_end = time.time()\n","    print(f\"time={t_end-t:.3e}s\")\n","    print(f\"x_sor:\\n{x_sor}\")\n","    print(f\"niter_sor:\\n{niter_sor}\")\n","    print(f\"inc_sor:\\n{inc_sor}\")\n"]},{"cell_type":"markdown","source":["*Note:* dans ce cas la méthode SOR doit diverger, c&#8217;est effectivement le cas.\n\n","Considérons, à présent, une matrice symétrique définie positive afin de vérifier que dans ce cas [la condition $0 < \\omega < 2$](#thm:3) est nécessaire et suffisante pour la convergence de la méthode SOR.\n\n","Vérifions que la méthode SOR converge pour un échantillonage de $]0,2[$\n"],"metadata":{"node_name":"admonition"}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["omegas=np.logspace(1e-2,1.99,20)\n","ok = True\n","for omega in omegas:\n","    # testons les méthodes SOR pour omega\n","    for sor in [sor1]:\n","        t = time.time()\n","        [x_sor, niter_sor, inc_sor] = sor(A, np.ones(4), np.zeros(4), omega=1.1, tol=1e-6, maxiter=100)\n","        t_end = time.time()\n","        ok &= (inc_sor[-1] < 1e-6)\n","assert ok == True\n","print(f\"toutes les méthodes SOR convergent pour omega dans un échantillonage de l'intervalle ]0,2[: {ok}\")\n"]},{"cell_type":"markdown","source":["*Note:* dans ce cas, la méthode SOR converge.\n"],"metadata":{"node_name":"admonition"}}],"metadata":{"language_info":{"name":"python","version":"3.9.1"},"kernelspec":{"name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":4}