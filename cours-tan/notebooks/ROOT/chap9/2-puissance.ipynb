{"cells":[{"cell_type":"markdown","source":["# Méthode de la puissance itérée\n\n","## Introduction\n\n","Comme on l&#8217;a vu dans certains problèmes précédents, la connaissance du spectre de A (c&#8217;est-à-dire de l&#8217;ensemble de toutes ses valeurs propres) n&#8217;est pas toujours nécessaire.\n","Souvent, seules importent les valeurs propres extrémales, c&#8217;est-à-dire celles ayant les plus grands et plus petits modules.\n","Soit A une matrice carrée d&#8217;ordre $n$. Supposons que ses valeurs propres soient rangées comme suit\n","\n$$\n\\left|\\lambda_1\\right|>\\left|\\lambda_2\\right| \\geq\\left|\\lambda_3\\right| \\geq \\ldots \\geq\\left|\\lambda_n\\right| .\n$$\n","Remarquer, en particulier, que $\\left|\\lambda_1\\right|$ est distinct des autres modules des valeurs propres de $\\mathrm{A}$. Notons $\\mathbf{x}_1$ un vecteur propre de norme 1 associé à $\\lambda_1$. Si les vecteurs propres de A sont linéairement indépendants, $\\lambda_1$ et $\\mathbf{x}_1$ peuvent être calculés par la méthode itérative suivante, appelée méthode de la puissance :\n","étant donné un vecteur initial arbitraire $\\mathbf{x}^{(0)} \\in \\mathbb{C}^n$, poser $\\mathbf{y}^{(0)}=\\mathbf{x}^{(0)} /\\left\\|\\mathbf{x}^{(0)}\\right\\|$, puis calculer\n","pour $k=1,2, \\ldots$\n","\n$$\n\\mathbf{x}^{(k)}=\\mathrm{A} \\mathbf{y}^{(k-1)}, \\quad \\mathbf{y}^{(k)}=\\frac{\\mathbf{x}^{(k)}}{\\left\\|\\mathbf{x}^{(k)}\\right\\|}, \\quad \\lambda^{(k)}=\\left(\\mathbf{y}^{(k)}\\right)^H \\mathrm{~A} \\mathbf{y}^{(k)}\n$$\n","*Note:* Remarquer qu&#8217;on trouve par récurrence que $\\mathbf{y}^{(k)}=\\beta^{(k)} \\mathrm{A}^k \\mathbf{y}^{(0)}$ où $\\beta^{(k)}=\\left(\\Pi_{i=1}^k\\left\\|\\mathbf{x}^{(i)}\\right\\|\\right)^{-1}$ pour $k \\geq 1$. **La présence des puissances de $\\mathrm{A}$ explique le nom de la méthode.**\n","Dans la section suivante, nous verrons que cette méthode consiste à construire une suite de vecteurs $\\left\\{\\mathbf{y}^{(k)}\\right\\}$ de norme 1 qui, quand $k \\rightarrow$ $\\infty$, s&#8217;alignent le long de la direction du vecteur propre $\\mathbf{x}_1$. Les erreurs $\\left\\|\\mathbf{y}^{(k)}-\\mathbf{x}_1\\right\\|$ et $\\left|\\lambda^{(k)}-\\lambda_1\\right|$ sont proportionnelles au rapport $\\left|\\lambda_2 / \\lambda_1\\right|^k$ dans le cas d&#8217;une matrice quelconque. Si $A$ est réelle et symétrique, on peut même prouver que $\\left|\\lambda^{(k)}-\\lambda_1\\right|$ est en fait proportionnel à $\\left|\\lambda_2 / \\lambda_1\\right|^{2 k}$ (voir [GL96, Chapitre 8]). Dans tous les cas, on a $\\lambda^{(k)} \\rightarrow \\lambda_1$ pour $k \\rightarrow \\infty$.\n","## Implémentation\n\n","La méthode de la puissance, détaillée ci-dessous, est une technique itérative permettant de trouver la valeur propre de plus grand module d&#8217;une matrice $A$. L&#8217;algorithme poursuit ses itérations jusqu&#8217;à ce que la différence relative entre deux approximations successives de la valeur propre soit inférieure à un seuil de tolérance fixé $\\varepsilon$. Autrement dit, l&#8217;algorithme s&#8217;arrête lorsque :\n","\n$$\n\\left| \\lambda^{(k)} - \\lambda^{(k-1)} \\right| < \\varepsilon \\left| \\lambda^{(k)} \\right|,\n$$\n","où $\\lambda^{(k)}$ est l&#8217;approximation de la valeur propre à l&#8217;itération $k$, et $\\varepsilon$ est la tolérance prédéterminée.\n","Les paramètres d&#8217;entrée comprennent la matrice $A$ sur laquelle appliquer la méthode, la tolérance $\\text{tol}$ utilisée pour le critère d&#8217;arrêt, le nombre maximal d&#8217;itérations $\\text{nmax}$, et le vecteur initial $x_0$.\n","Les valeurs retournées par la fonction incluent $\\lambda$, la valeur propre dominante de $A$, un vecteur propre associé à cette valeur propre, et le nombre d&#8217;itérations réalisées pour atteindre la convergence selon le critère établi.\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["Unresolved directive in 2-puissance.adoc - include::example$tan/eig/eigpower.py[]\n"]},{"cell_type":"markdown","source":["## Exemples\n\n","*Exemple: famille de matrice $A(\\alpha)$*\\\n","Considérons la famille de matrices\n\n","\n$$\n\\mathrm{A}(\\alpha)=\\left[\\begin{array}{cccc}\n\\alpha & 2 & 3 & 13 \\\\\n5 & 11 & 10 & 8 \\\\\n9 & 7 & 6 & 12 \\\\\n4 & 14 & 15 & 1\n\\end{array}\\right], \\quad \\alpha \\in \\mathbb{R} .\n$$\n\n","On veut approcher la valeur propre de plus grand module par la méthode de la puissance.\n","Quand $\\alpha=30$, les valeurs propres de la matrice sont données par $\\lambda_1=39.396, \\lambda_2=17.8208, \\lambda_3=-9.5022$ et $\\lambda_4=0.2854$ (où on se limite aux 4 premiers chiffres après la virgule).\n","La méthode approche $\\lambda_1$ en 22 itérations avec une tolérance $\\varepsilon=10^{-10}$ et $\\mathbf{x}^{(0)}=\\mathbf{1}^T$.\n","Cependant, si $\\alpha=-30$, il faut 708 itérations.\n\n","Cette différence de comportement peut s&#8217;expliquer en remarquant que dans le dernier cas on a $\\lambda_1=-30.643, \\lambda_2=29.7359, \\lambda_3=-11.6806$ et $\\lambda_4=0.5878$.\n","Donc, $\\left|\\lambda_2\\right| /\\left|\\lambda_1\\right|$ est proche de un (0.9704).\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["from tan.eig.eigpower import eigpower\n","\n","# Matrice A pour alpha = 30\n","alpha = 30\n","A = np.array([[alpha, 2, 3, 13],\n","              [5, 11, 10, 8],\n","              [9, 7, 6, 12],\n","              [4, 14, 15, 1]])\n","\n","# Calcul de la valeur propre de plus grand module\n","lambda_max, x_max, iterations = eigpower(A)\n","print(\"Pour alpha = 30:\")\n","print(f\"Valeur propre approximée: {lambda_max}\")\n","print(f\"Vecteur propre associé: {x_max}\")\n","print(f\"Iterations: {iterations}\")\n","\n","# Matrice A pour alpha = -30\n","alpha = -30\n","A = np.array([[alpha, 2, 3, 13],\n","              [5, 11, 10, 8],\n","              [9, 7, 6, 12],\n","              [4, 14, 15, 1]])\n","\n","# Calcul de la valeur propre de plus grand module\n","lambda_max, x_max, iterations = eigpower(A)\n","print(\"\\nPour alpha = -30:\")\n","print(f\"Valeur propre approximée: {lambda_max}\")\n","print(f\"Vecteur propre associé: {x_max}\")\n","print(f\"Iterations: {iterations}\")\n"]},{"cell_type":"markdown","source":["*Exemple: connections urbaines*\\\n","Revenons sur le [problème de connections urbaines](chap9/1-motivations.ipynb#prob:connections).\n","On note $A \\in \\mathbb{R}^{11 \\times 11}$ la matrice associée au réseau ferroviaire, i.e. la matrice dont les coefficients $a_{i j}$ sont égaux à un s&#8217;il y a une connexion directe entre la ville $i$ et la ville $j$, et à zéro sinon. En posant $tol=1.e-12$ et $\\mathrm{x} 0=$ ones $(11,1)$, `eigpower` retourne, après 26 itérations, l&#8217;approximation suivante d&#8217;un vecteur propre (de norme 1) associé à la valeur propre de A de plus grand module :\n\n","La ville associée à la première composante (plus grand module) de $x$, Paris, est la mieux desservie. Celle associé à la dernière composante (plus petit module) de x, Nice, est la moins bien desservie.\n\n","*Note:* Remarquer que notre analyse ne prend en compte que l&#8217;existence de connections ferroviaires entre les villes, mais pas la fréquence des trains.\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["import numpy as np\n","\n","# Liste des villes\n","cities = [\"Paris\", \"Lyon\", \"Marseilles\", \"Strasbourg\", \"Bordeaux\",\n","          \"Nantes\", \"Lille\", \"Toulouse\", \"Nice\", \"Rennes\", \"Grenoble\"]\n","\n","# Création d'une matrice de transition vide\n","n = len(cities)\n","transition_matrix = np.zeros((n, n))\n","\n","# Indices pour chaque ville\n","city_indices = {city: index for index, city in enumerate(cities)}\n","\n","# Connexions\n","connections = {\n","    \"Paris\": [\"Strasbourg\", \"Lyon\", \"Lille\", \"Rennes\", \"Bordeaux\"],\n","    \"Lyon\": [\"Marseilles\", \"Strasbourg\", \"Paris\", \"Nice\",\"Grenoble\"],\n","    \"Strasbourg\": [\"Paris\", \"Lyon\", \"Rennes\"],\n","    \"Rennes\": [\"Strasbourg\", \"Nantes\"],\n","    \"Bordeaux\": [\"Toulouse\"],\n","    \"Marseilles\": [\"Lyon\", \"Nice\"],\n","    # Ajouter plus de connexions si nécessaire\n","}\n","\n","# Remplir la matrice de transition avec les connexions\n","for city, connected_cities in connections.items():\n","    for connected_city in connected_cities:\n","        i, j = city_indices[city], city_indices[connected_city]\n","        transition_matrix[i, j] = 1  # Ville connectée\n","        transition_matrix[j, i] = 1  # Connexion bidirectionnelle\n","\n","# Affichage de la matrice de transition\n","print(\"Matrice de transition des connexions TGV :\")\n","print(transition_matrix)\n","\n","from tan.eig.eigpower import eigpower\n","l, x, iter = eigpower(transition_matrix)\n","print(f\"Vecteur propre max de la matrice de transition : {x}\")\n"]},{"cell_type":"markdown","source":["## Analyse de convergence\n\n","Les vecteurs propres $\\mathbf{x}_1, \\ldots, \\mathbf{x}_n$ de $A$ forment une base de $\\mathbb{C}^n$, puisqu&#8217;on les a supposés linéairement indépendants. On peut donc écrire $\\mathbf{x}^{(0)}$ et $\\mathbf{y}^{(0)}$ comme\n","\n$$\n\\mathbf{x}^{(0)}=\\sum_{i=1}^n \\alpha_i \\mathbf{x}_i, \\mathbf{y}^{(0)}=\\beta^{(0)} \\sum_{i=1}^n \\alpha_i \\mathbf{x}_i, \\quad \\text { avec } \\beta^{(0)}=1 /\\left\\|\\mathbf{x}^{(0)}\\right\\| \\text { et } \\alpha_i \\in \\mathbb{C} .\n$$\n","A la première itération, la méthode de la puissance donne\n","\n$$\n\\mathbf{x}^{(1)}=\\mathrm{A} \\mathbf{y}^{(0)}=\\beta^{(0)} \\mathrm{A} \\sum_{i=1}^n \\alpha_i \\mathbf{x}_i=\\beta^{(0)} \\sum_{i=1}^n \\alpha_i \\lambda_i \\mathbf{x}_i\n$$\n","et, de même,\n","\n$$\n\\mathbf{y}^{(1)}=\\beta^{(1)} \\sum_{i=1}^n \\alpha_i \\lambda_i \\mathbf{x}_i, \\quad \\beta^{(1)}=\\frac{1}{\\left\\|\\mathbf{x}^{(0)}\\right\\|\\left\\|\\mathbf{x}^{(1)}\\right\\|} .\n$$\n","A l&#8217;étape $k$, on a\n","\n$$\n\\mathbf{y}^{(k)}=\\beta^{(k)} \\sum_{i=1}^n \\alpha_i \\lambda_i^k \\mathbf{x}_i, \\quad \\beta^{(k)}=\\frac{1}{\\left\\|\\mathbf{x}^{(0)}\\right\\| \\cdots\\left\\|\\mathbf{x}^{(k)}\\right\\|}\n$$\n","et donc\n","\n$$\n\\mathbf{y}^{(k)}=\\lambda_1^k \\beta^{(k)}\\left(\\alpha_1 \\mathbf{x}_1+\\sum_{i=2}^n \\alpha_i \\frac{\\lambda_i^k}{\\lambda_1^k} \\mathbf{x}_i\\right) .\n$$\n","Comme $\\left|\\lambda_i / \\lambda_1\\right|<1$ pour $i=2, \\ldots, n$, le vecteur $\\mathbf{y}^{(k)}$ tend à s&#8217;aligner le long de la direction du vecteur propre $\\mathbf{x}_1$ quand $k$ tend vers $+\\infty$, à condition que $\\alpha_1 \\neq 0$. Cette condition sur $\\alpha_1$, impossible à assurer en pratique puisque $\\mathbf{x}_1$ est inconnu, n&#8217;est en fait pas restrictive. En effet, les erreurs d&#8217;arrondi entraînent l&#8217;apparition d&#8217;une composante non nulle selon $\\mathbf{x}_1$, même quand le vecteur initial $\\mathbf{x}^{(0)}$ n&#8217;en a pas (on peut dire que c&#8217;est un des rares cas où les erreurs d&#8217;arrondi nous aident!).\n","Il est possible de montrer que la méthode de la puissance converge même si $\\lambda_1$ est une racine multiple de $p_{\\mathrm{A}}(\\lambda)$. En revanche, elle ne converge pas quand il existe deux valeurs propres distinctes de même module maximal. Dans ce cas, la suite $\\lambda^{(k)}$ oscille entre deux valeurs et ne converge vers aucune limite.\n","*Exemple: famille de matrices $A(\\alpha)$*\\\n","Considérons la matrice $\\mathrm{A}(\\alpha)$ de [l&#8217;exemple](#ex:1), avec $\\alpha=16$. Un vecteur propre $\\mathbf{x}_1$ de norme 1 associé à $\\lambda_1$ est $(1 / 2,1 / 2,1 / 2,1 / 2)^T$. Choisissons (à dessein!) le vecteur initial $(2,-2,3,-3)^T$, qui est orthogonal à $\\mathbf{x}_1$. On indique sur la Figure 6.3 la quantité $\\cos \\left(\\theta^{(k)}\\right)=\\left(\\mathbf{y}^{(k)}\\right)^T \\mathbf{x}_1 /\\left(\\left\\|\\mathbf{y}^{(k)}\\right\\|\\left\\|\\mathbf{x}_1\\right\\|\\right)$. On voit qu&#8217;après environ 30 itérations de la méthode de la puissance, le cosinus tend vers -1 et l&#8217;angle vers $\\pi$, tandis que la suite $\\lambda^{(k)}$ approche $\\lambda_1=34$. Avec la méthode de la puissance, on a donc construit, grâce aux erreurs d&#8217;arrondi, une suite de vecteurs $\\mathbf{y}^{(k)}$ dont les composantes selon $\\mathbf{x}_1$ sont de plus en plus significatives.\n"],"metadata":{}},{"cell_type":"code","execution_count":0,"metadata":{"slideshow":{"slide_type":"fragment"}},"outputs":[],"source":["from tan.eig.eigpower import eigpower\n","import numpy as np\n","\n","# Matrice A pour alpha = 16\n","alpha = 16\n","A = np.array([[alpha, 2, 3, 13],\n","              [5, 11, 10, 8],\n","              [9, 7, 6, 12],\n","              [4, 14, 15, 1]])\n","\n","# Calcul de la valeur propre de plus grand module\n","lambda_max, x_max, iterations = eigpower(A, tol=1.e-12, nmax=1000, x0=np.array([2, -2, 3, -3]))\n","print(f\"Valeur propre approximée: {lambda_max}\")\n","print(f\"Vecteur propre associé: {x_max}\")\n","print(f\"Iterations: {iterations}\")\n","\n"]},{"cell_type":"markdown","source":["## Résultats théoriques\n\n","Dans cette section, on se fixe $A \\in \\mathscr{M}_n({\\mathbb{C}})$ et on note\n","$\\mathop{\\mathrm{\\mathrm{Sp}}}(A) = \\{ \\lambda_1, \\dots, \\lambda_k \\}$\n","les valeurs propres de $A$, d’indice $n_k$, de sorte\n","que le polynôme minimal de $A$ est\n","\n$$\n\\pi_A(X) = \\prod_{i=1}^k (X-\\lambda_k)^{n_k}.\n$$\n","On note $E_k$ les sous espaces caractéristiques associés à\n","$\\lambda_k$:\n","\n$$\nE_k = \\mathop{\\mathrm{Ker}}(A-\\lambda_k)^{n_k}, \\quad {\\mathbb{C}}^n = \\bigoplus_{i=1}^k E_k.\n$$\n","*Théorème 7*\\\n","On suppose que $\\lambda_1$ est de module\n","maximal (strictement): pour $i =2, \\dots, k$,\n","$|\\lambda_k| < |\\lambda_1|$; et que $n_1=1$.\n\n","Pour $x \\in {\\mathbb{C}}^n$, on définit la suite récurrente $(x_n)$ par\n","$x_0 = x$ et $x_{n+1} = \\| Ax_n \\|^{-1} Ax_n$.\n\n","Si $x = e_1 + y$ avec $e_1 \\in E_1$ non nul et\n","$y \\in F_1 :=\\bigoplus_{i=2}^k E_k$, alors la suite\n","$(x_n)$ est bien définie et\n","$\\displaystyle x_n - \\frac{\\lambda_1^n e_1}{\\| \\lambda^n e_1 \\|} \\to 0$.\n","En particulier, $x_n^* A x_{n} \\to \\lambda_1$._\n\n","La condition $n_1=1$ est automatiquement vérifié si\n","$\\lambda_1$ est simple. C’est le cas par exemple pour les\n","opérateurs de Perron-Frobenius.\n","* **Cas diagonalisable**\\\nOn décompose $x = e_1 + \\cdots + e_k$ et\n\n  \n$$\nx_n = \\frac{1}{z_n} \\left( \\lambda_1^n e_1 + \\cdots + \\lambda_k^n e_k \\right), \\quad z_n = \\|  \\lambda_1^n e_1 + \\cdots + \\lambda_k^n e_k \\|.\n$$\n\n  Comme $\\lambda_1$ est de module maximal strict,\n\n  \n$$\n\\lambda_2^n e_2 + \\cdots  + \\lambda_k^n e_k = o(\\lambda_1^n).\n$$\n\n  Ainsi, $z_n = |\\lambda_1|^n (\\| e_1 \\| + o(1))$ et donc\n\n  \n$$\nx_n = \\frac{1}{z_n} \\lambda_1^n (e_1 + o(1)) = \\frac{\\lambda_1^n}{|\\lambda_1|^n} \\frac{e_1}{\\| e_1 \\|} + o(1).\n$$\n\n\n* **Cas général**\\\nComme $n_1$, $E_1$ est l’ensemble des vecteurs propres associé à $\\lambda_1$. En particulier $Ae_1 = \\lambda_1 e_1$.\n\n","On note $B = A|_{F_1}$ de sorte que\n","$\\mathop{\\mathrm{\\mathrm{Sp}}}(B) = \\{ \\lambda_2, \\dots, \\lambda_k \\}$,\n","et $\\tilde A = 0_{E_1} \\oplus B$. On choisit pour\n","$\\| \\cdot \\|$ une norme d’opérateur de sorte que\n","$\\| \\tilde A \\| \\leqslant(1-\\varepsilon) |\\lambda_1|$ pour un\n","certain $\\varepsilon>0$.\n\n","On note $x_n = e_{1,n} + y_n$ la décomposition adaptée à\n","$E_1 \\oplus F_1$. Alors on a\n\n","\n$$\nA x_n = Ae_{1,n} + Ay_n = \\lambda_1 e_{1,n} + Ay_n,\n$$\n\n","et comme $F_1$ est stable par $A$, on en déduit que\n\n","\n$$\ne_{1,n+1} = \\frac{1}{\\| Ax_n \\|} \\lambda_1 e_{1,n}, \\quad y_{n+1} = \\frac{1}{\\| Ax_n \\|} Ay_n.\n$$\n\n","Comme $y_n \\in F_1$,\n","$\\| Ay_n \\| \\leqslant(|\\lambda_1|-\\varepsilon) \\| y_n \\|$.\n","Ainsi\n\n","\n$$\n\\frac{\\| y_{n+1} \\|}{\\| e_{1,n+1} \\|} = \\frac{\\| Ay_n \\|}{\\| \\lambda_1 e_{1,n} \\|} \\leqslant(1-\\varepsilon) \\frac{\\| y_n \\|}{\\| e_{1,n} \\|},\n$$\n\n","puis par récurrence immédiate,\n\n","\n$$\n\\| y_n \\| \\leqslant(1-\\varepsilon)^n \\| y_0 \\| \\| e_{1,n} \\| = o( \\| e_{1,n} \\|).\n$$\n\n","Ceci entraine que $\\| e_{1,n} \\| \\to 1$ et\n","$\\| y_n \\| \\to 0$. Or par récurrence, il existe\n","$r_n >0$ tel que $e_{1,n} = r_n \\lambda_1^n e_1$. Vu\n","la condition de norme, $r_n/\\| \\lambda_1^n e_1 \\| \\to 1$. Donc\n\n","\n$$\nx_n =  \\frac{\\lambda_1^n e_1}{\\| \\lambda^n e_1 \\|} + o(1). \\qedhere\n$$\n","On en déduit un algorithme qui permet d’obtenir la plus grande valeur propre, ainsi qu’un vecteur propre associé.\n","*Algorithme de la puissance itérée:*\\\n","\n$$\n\\begin{aligned}\ny_{k+1} & = A x_k \\\\\nx_{k+1} & = \\frac{y_{k+1}}{\\|  y_{k+1} \\|} \\\\\n\\sigma_k & = (x_k)^* y_{k+1}.\n\\end{aligned}\n$$\n\n","Alors $\\sigma_k \\to \\lambda_1$ et $d(E_1,x_{k+1}) \\to 0$.\n","*Note:* En utilisant $A^{-1}$ au lieu de $A$, on peut évaluer la plus petite valeur propre de $A$ (en module).\n","*Note:* En appliquant à $(A-\\mu)^{-1}$, on évalue la valeur propre de $A$ la plus proche de $\\mu$.\n","C’est utile, si on a pu déjà localiser grossièrement une valeur propre $\\lambda$ de $A$ (par exemple grâce aux disque de Gerschgorin).\n","*Algorithme de la puissance inverse avec translation:*\\\n","\n$$\n\\begin{aligned}\ny_{k+1} & \\text{ solution de } (A-\\mu I_n) y_{k+1} = x_k \\\\\nx_{k+1} & = \\frac{y_{k+1}}{\\|  y_{k+1} \\|} \\\\\n\\sigma_{k+1} & = \\mu + (x_k)^* y_{k+1}.\n\\end{aligned}\n$$\n\n","Alors $\\sigma_k \\to \\lambda_i$, valeur propre de $A$ la plus proche de $\\mu$, et $d(E_i,x_k) \\to 0$.\n\n","On peut accélérer l’algorithme en utilisant $\\sigma_k$ au lieu\n","de $\\mu$ à chaque étape (meilleure approximation de\n","$\\lambda_i$).\n"],"metadata":{}}],"metadata":{"language_info":{"name":"python","version":"3.9.1"},"kernelspec":{"name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":4}